<!doctype html>
<html lang="es">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Introducción a las redes neuronales — JAFS</title>
  <meta name="description" content="Si intentamos resolver un problema tan simple como la operación XOR, nos encontraremos con una sorpresa. Ya que no podremos resolverla con una neurona artificial." />
  <meta name="author" content="José Antonio Fuentes Santiago" />
  <meta name="keywords" content="José Antonio Fuentes Santiago, Programación, Redes Neuronales, Inteligencia Artificial, IA, JavaScript" />
  <meta name="article:published_time" content="2025-07-20T18:12:04.000Z" />

  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article" />
  <meta property="og:url" content="https://jafs.github.io/articles/posts/20250720.html" />
  <meta property="og:title" content="Introducción a las redes neuronales" />
  <meta property="og:description" content="Si intentamos resolver un problema tan simple como la operación XOR, nos encontraremos con una sorpresa. Ya que no podremos resolverla con una neurona artificial." />
  <meta property="og:site_name" content="JAFS" />
  <meta property="og:locale" content="es_ES" />
  <meta property="og:image" content="/images/redes-neuronales.webp" />

  <meta property="article:published_time" content="2025-07-20T18:12:04.000Z" />

  <meta property="article:author" content="José Antonio Fuentes Santiago" />

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:title" content="Introducción a las redes neuronales" />
  <meta name="twitter:description" content="Si intentamos resolver un problema tan simple como la operación XOR, nos encontraremos con una sorpresa. Ya que no podremos resolverla con una neurona artificial." />
  <meta name="twitter:image" content="/images/redes-neuronales.webp" />

  <!-- Canonical URL -->
  <link rel="canonical" href="https://jafs.github.io/articles/posts/20250720.html" />

  <!-- Favicons -->
  <link rel="icon" type="image/png" href="/favicon-96x96.png" sizes="96x96" />
  <link rel="icon" type="image/svg+xml" href="/favicon.svg" />
  <link rel="shortcut icon" href="/favicon.ico" />
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="manifest" href="/site.webmanifest" />

  <link rel="stylesheet" href="/css/dist.css">
  <link rel="stylesheet" href="/css/github-dark.min.css">

  <!-- JSON-LD Structured Data -->
  <script type="application/ld+json">
  {
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Introducción a las redes neuronales",
  "author": {
    "@type": "Person",
    "name": "José Antonio Fuentes Santiago"
  },
  "publisher": {
    "@type": "Person",
    "name": "José Antonio Fuentes Santiago"
  },
  "description": "Si intentamos resolver un problema tan simple como la operación XOR, nos encontraremos con una sorpresa. Ya que no podremos resolverla con una neurona artificial.",
  "url": "https://jafs.github.io/articles/posts/20250720.html",
  "inLanguage": "es",
  "datePublished": "2025-07-20T18:12:04.000Z"
}
  </script>
</head>
<body class="bg-gray-50 text-gray-900">
  <header class="bg-black text-white py-4 shadow-md">
    <div class="max-w-4xl mx-auto px-4 flex items-center justify-between">
      <a href="/" class="text-2xl font-bold">
        <img src="/images/logo-mini.webp" alt="JAFS" class="inline-block w-8 h-8 mr-2 align-middle" />
      </a>
      <div class="flex items-center gap-4">
        <nav class="flex gap-4">
          <a href="/index.html" class="text-gray-300 hover:text-white transition-colors">Inicio</a>
          <a href="/articles/" class="text-gray-300 hover:text-white transition-colors">Artículos</a>
          <a href="/books/" class="text-gray-300 hover:text-white transition-colors">Libros</a>
          <a href="/about.html" class="text-gray-300 hover:text-white transition-colors">Sobre mí</a>
        </nav>
        <form action="/search.html" method="get">
          <input type="search" name="q" placeholder="Buscar..." class="px-3 py-2 rounded bg-gray-800 text-white text-sm placeholder-gray-400 border border-gray-700 focus:outline-none focus:border-cyan-500 focus:ring-1 focus:ring-cyan-500 w-40" aria-label="Buscar artículos" />
        </form>
      </div>
    </div>
  </header>
  <main class="max-w-4xl mx-auto px-4 py-8">
    <article class="prose prose-lg max-w-none bg-white rounded-lg shadow-sm p-8">
      <h1 class="text-4xl font-bold mb-2">Introducción a las redes neuronales</h1>
      <p class="text-gray-600 text-sm mb-6">20-07-2025</p>
      <img src="/images/redes-neuronales.webp" alt="Redes neuronales" />
      <p>En el <a href="/articles/posts/20250622.html">artículo anterior</a> pudimos revisar en qué consisten las neuronas artificiales, y además vimos cómo poder implementar una neurona en JavaScript. Si aún no lo has leído, te recomiendo que empieces por ahí para entender la base de lo que vamos a ver ahora.</p>
      <p>Si aún así quieres empezar a leer este artículo, a modo de resumen, en el anterior hablábamos de neuronas como pequeñas funciones matemáticas que ajustaban pesos y sesgos para intentar dar una salida lo más precisa posible a partir de unas entradas. Hasta ahí todo sencillo.</p>
      <p>Pero, si intentamos resolver un problema tan simple como la operación <strong>XOR</strong>, nos encontraremos con una sorpresa. Lo primero de todo, recordemos su tabla de la verdad:</p>
<pre><code class="language-text">A | B | Salida
0 | 0 | 0
0 | 1 | 1
1 | 0 | 1
1 | 1 | 0
</code></pre>
<p>El problema de XOR es que <strong>no es linealmente separable</strong>. Una neurona, como la que programamos en el artículo anterior, sólo puede establecer un límite mediante una recta (o un plano si hablamos de más dimensiones) para separar las salidas, o dicho de otra forma, sólo puede crear separaciones lineales entre las entradas y las salidas. En cambio, las capas ocultas permiten que la red combine múltiples límites simples para formar decisiones más complejas y precisas.</p>
<h2 id="¿qué-es-una-red-neuronal">¿Qué es una red neuronal?</h2>
<p>Una <strong>red neuronal artificial</strong> es un conjunto de neuronas conectadas entre sí que trabajan juntas para procesar información. Se inspiran en cómo funciona el cerebro humano, aunque de forma muy simplificada. Ya vimos, que cada neurona recibe entradas, las transforma aplicando una función matemática (lo que llamamos activación) y genera una salida. Pues bien, en una red neuronal, esta salida llega a otras neuronas conectadas. Al unir muchas neuronas, se consigue que la red pueda aprender patrones complejos que una sola neurona no es capaz de distinguir.</p>
<p>Las redes al igual que las cebollas, como diría Shrek, se organizan en <strong>capas</strong>:</p>
<ul>
<li><strong>Capa de entrada</strong>: Recibe los datos iniciales. Por ejemplo, si queremos reconocer imágenes, la capa de entrada recibe los píxeles.</li>
<li><strong>Capas ocultas</strong>: Son las encargadas de procesar la información internamente. Cada neurona en estas capas intenta encontrar relaciones, patrones o combinaciones que sean útiles para llegar a una salida correcta. Su nombre viene de que no vemos directamente sus resultados como usuarios.</li>
<li><strong>Capa de salida</strong>: Es la que tiene como entradas los resultados de las capas ocultas, y según estados resultados da la respuesta final.</li>
</ul>
<p>Las redes pueden tener tantas capas ocultas como queramos, pero incluso con una capa podemos resolver problemas como el XOR, como veremos a continuación. Ya que esta aproximación nos permite comenzar a usar la IA como realmente la conocemos, dejando atrás los problemas muy sencillos que podía resolver una única neurona, para pasar a resolver problemas más complejos como:</p>
<ul>
<li>Reconocimiento de imágenes</li>
<li>Traducción automática</li>
<li>Diagnóstico médico</li>
<li>Coches autónomos</li>
</ul>
<p>Y un largo etcétera de posibilidades.</p>
<h2 id="construyendo-nuestra-primera-red-neuronal">Construyendo nuestra primera red neuronal</h2>
<p>Para resolver la operación XOR, nuestra red neuronal va a ser muy sencilla:</p>
<ul>
<li>La <strong>capa oculta</strong> tendrá dos neuronas.</li>
<li>Y tendremos una <strong>neurona final</strong> de salida.</li>
</ul>
<p>Esto es suficiente para resolver XOR. Cada neurona de la capa oculta aprenderá a distinguir una de las condiciones necesarias para que XOR funcione. La neurona de salida simplemente combinará esa información.</p>
<p>Para entender cómo &quot;mapeamos&quot; de las neuronas ocultas a la de salida, piensa que cada neurona oculta detecta un patrón concreto (por ejemplo, que A sea 1 y B sea 0). La neurona de salida aprenderá a usar esas &quot;pistas&quot; que proporcionan las neuronas de la capa oculta para decidir su salida.</p>
<h2 id="código-y-explicación-paso-a-paso">Código y explicación paso a paso</h2>
<h3 id="clase-neuron">Clase Neuron</h3>
<p>En el artículo anterior ya vimos la clase Neuron. Aquí os pongo que métodos públicos tiene a modo de recordatorio:</p>
<pre><code class="language-javascript">class Neuron {
  /**
   * &quot;Activa&quot; la neurona a partir de las entradas proporcionadas, o
   * dicho de otro modo, hace que la neurona nos dé un resultado.
   */
  activate(inputs) { }

  /**
   * Se encarga del entrenamiento de la neurona dado un conjunto de
   * datos de entrada con sus correspondientes salidas y el número de
   * veces que hay que iterar los datos para &quot;consolidar&quot; esos resultados.
   */
  training(dataset, epochs) { }

  /**
   * Este método es muy importante, ya que ajusta los pesos y el sesgo
   * para que la neurona pueda &quot;predecir&quot; mejor los resultados.
   */
  adjust(inputs, gradient) { }
}
</code></pre>
<h3 id="definiendo-la-red-neuronal">Definiendo la red neuronal</h3>
<p>El constructor simplemente inicializa la capa oculta y genera la neurona de salida. Aunque sólo es necesario dos neurona para resolver la operación XOR, ya hemos dejado el código genérico para recibir cualquier número de neuronas.</p>
<pre><code class="language-javascript">class NeuralNetowrk {
  constructor(inputsNumber, activationFunction, derivateFunction, neuronsNumber, learningRate = 0.1) {
    this.#derivateFunction = derivateFunction;

    this.#hiddenNeurons = [];
    for (let i = 0; i &lt; neuronsNumber; i++) {
      this.#hiddenNeurons.push(
        new Neuron(
          inputsNumber, activationFunction,
          this.#derivateFunction, learningRate
       ));
     }

    // Create output neuron, which takes hidden neuron outputs as inputs
    this.#outputNeuron = new Neuron(
      neuronsNumber, activationFunction, this.#derivateFunction,
      learningRate
    );
  }
}
</code></pre>
<p>El método que activa la red neuronal, difiere del de una neurona. En este caso activaremos todas las neuronas de la capa oculta, y una vez obtenidos sus resultados, será lo que pasemos a la neurona de salida para que nos proporcione el resultado final:</p>
<pre><code class="language-javascript">activate(inputs) {
  const hiddenOutputs = this.#hiddenNeurons.map(
    neuron =&gt; neuron.activate(inputs)
  );
  return this.#outputNeuron.activate(hiddenOutputs);
}
</code></pre>
<p>El método de entrenamiento público, será exactamente el mismo que el de una neurona ya que simplemente iterará el conjunto de datos el número de pasos (épocas) necesarias.</p>
<p>En cada época, comenzaremos con el entrenamiento, algo que a nivel de código tampoco es demasiado complejo en su método principal:</p>
<pre><code class="language-javascript">#train(inputs, expectedOutput) {
  // Esta parte es muy similar a lo que hace una neurona, que es obtener
  // una predicción tanto para las capas ocultas como para la neurona de
  // salida.
  const hiddenOutputs = this.#hiddenNeurons.map(n =&gt; n.activate(inputs));
  const computedOutput = this.#outputNeuron.activate(hiddenOutputs);

  // Igualmente, calculamos la desviación del error, basándonos en la
  // predicción generada por la neurona de salida.
  const adjustValue = calculateAdjust(
    expectedOutput, computedOutput, this.#derivateFunction
  );

  // Ahora debemos propagar la desviación del error para hacer ajustes y
  // corregir tanto la neurona de salida como las neuronas de la capa
  // oculta
  this.#adjustWeights(hiddenOutputs, inputs, adjustValue);
}
</code></pre>
<p>Y aquí comienza lo complicado, ya que como habréis visto en los comentarios del código anterior, es necesario propagar la desviación de error, no sólo de una neurona, sino a todas las de la red:</p>
<pre><code class="language-javascript">#adjustWeights(hiddenOutputs, inputs, adjust) {
  // Mandamos el ajuste a la neurona de salida
  this.#outputNeuron.adjust(hiddenOutputs, adjust);

  // Aquí mandamos el ajuste a las neuronas de la capa oculta. No podemos 
  // usar el ajuste de la neurona de salida directamente, sino que tenemos
  // que realizar dicho ajuste en base al peso de cada neurona de la capa
  // oculta, para que la desviación sea acorde con dicha neurona. A este
  // valor derivado del ajuste de la neurona de salida le llamamos
  // gradiente.
  for (let index = 0; index &lt; this.#hiddenNeurons.length; ++index) {
    const hiddenNeuron = this.#hiddenNeurons[index];

    const gradient = this.#computeGradient(
      hiddenNeuron.Output, this.#outputNeuron.Weights[index], adjust
    );

    hiddenNeuron.adjust(inputs, gradient);
  }
}

#computeGradient(output, weight, adjust) {
  return this.#derivateFunction(output) * weight * adjust;
}
</code></pre>
<h3 id="entrenando-la-red">Entrenando la red</h3>
<p>El entrenamiento es muy parecido al que realizamos con una sóla neurona, así que hemos aprovechado para hacer que la API pública de la red neuronal sea similar a la de una neurona.</p>
<pre><code class="language-javascript">const xorData = [
  { inputs: [0, 0], output: 0 },
  { inputs: [0, 1], output: 1 },
  { inputs: [1, 0], output: 1 },
  { inputs: [1, 1], output: 0 }
];

const neuralNetwork = new NeuralNetwork(
  2, activationSigmoid, derivateSigmoid, 2, 0.1
);
neuralNetwork.training(xorData, 50000);

// Si probamos ahora a imprimir los resultados (recordad que no nos
// devuelve un valor exacto sino una aproximación, de ahí que usemos la
// función Math.round().
console.log(Math.round(neuralNetwork.activate([0, 0]))); // Imprime 0
console.log(Math.round(neuralNetwork.activate([0, 1]))); // Imprime 1
console.log(Math.round(neuralNetwork.activate([1, 0]))); // Imprime 1
console.log(Math.round(neuralNetwork.activate([1, 1]))); // Imprime 0
</code></pre>
<p>Bien, el código que hemos visto nos permite generar una red neuronal de forma muy sencilla. Hay formas de desarrollarla mucho más avanzadas y correctas como sería usar un <strong>gradiente descendente</strong>, pero como siempre digo, eso será tema para otros artículos.</p>
<h2 id="resumiendo">Resumiendo...</h2>
<ul>
<li>Una <strong>neurona aislada</strong> es muy limitada, por lo que no sirve para operaciones complejas.</li>
<li>Cuando unimos varias neuronas y les permitimos aprender juntas generamos una <strong>red neuronal</strong>.</li>
<li>Incluso sin grandes frameworks, podemos construir pequeños ejemplos en JavaScript (o cualquier otro lenguage que se te ocurra) para entender las bases.</li>
<li>Hemos pasado de una neurona que &quot;resolvía&quot; operaciones muy sencillas, a una pequeña red que es capaz de resolver problemas imposibles para una sola.</li>
</ul>
<p>Espero que os haya servido para entender un poco más las bases de este apasionante mundillo.</p>
<p>El código del proyecto ya está actualizado en <a href="https://github.com/jafs/mini-ai">GitHub</a>, con la red neuronal. Podéis descargarlo, mejorarlo, experimentar y todo lo que se os ocurra.</p>
<p>Muchas gracias si habéis llegado hasta aquí. Nos vemos en el próximo artículo.</p>

    </article>
  </main>
  <footer class="bg-black text-white py-4 mt-12">
    <div class="max-w-4xl mx-auto px-4 flex flex-col items-center gap-4">
      <div class="flex gap-4">
        <a href="https://www.linkedin.com/in/joseafs/" target="_blank" rel="noopener noreferrer" class="text-white hover:text-gray-300 transition-colors" aria-label="LinkedIn">
          <img src="/images/linkedin.svg" alt="LinkedIn" class="w-6 h-6" />
        </a>
        <a href="https://www.youtube.com/@jafsdeveloper" target="_blank" rel="noopener noreferrer" class="text-white hover:text-gray-300 transition-colors" aria-label="YouTube">
          <img src="/images/youtube.svg" alt="YouTube" class="w-6 h-6" />
        </a>
        <a href="https://www.instagram.com/jafs_developer/" target="_blank" rel="noopener noreferrer" class="text-white hover:text-gray-300 transition-colors" aria-label="Instagram">
          <img src="/images/instagram.svg" alt="Instagram" class="w-6 h-6" />
        </a>
      </div>
      <div class="text-center">© 2025 — José Antonio Fuentes Santiago</div>
    </div>
  </footer>
  <script src="/js/highlight.min.js"></script>
  <script src="/js/main.js"></script>
</body>
</html>